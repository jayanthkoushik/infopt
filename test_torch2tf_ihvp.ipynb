{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "younger-electronics",
   "metadata": {},
   "source": [
    "# Test TF2 port of IHVP\n",
    "\n",
    "YJ Choe (yjchoe@cmu.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "available-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "from infopt.ihvp import IterativeIHVP, LowRankIHVP\n",
    "from infopt.ihvp_tf import IterativeIHVPTF\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "preceding-divide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.7.1\n",
      "tensorflow: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(\"torch:\", torch.__version__)\n",
    "print(\"tensorflow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "muslim-steal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: tensor([[-0.1396, -1.8070,  0.2753],\n",
      "        [-0.1218,  0.7186,  0.5395],\n",
      "        [ 1.2287,  0.6572, -0.8190],\n",
      "        [-1.7459,  0.5130,  0.2059]])\n",
      "tf: tf.Tensor(\n",
      "[[-0.1395616  -1.8070085   0.2752801 ]\n",
      " [-0.12175678  0.7186479   0.5395054 ]\n",
      " [ 1.228726    0.657225   -0.81902796]\n",
      " [-1.7459302   0.51304966  0.2058618 ]], shape=(4, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t_torch = torch.randn(4, 3)\n",
    "t_tf = tf.constant(t_torch.numpy())\n",
    "print(\"torch:\", t_torch)\n",
    "print(\"tf:\", t_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-matrix",
   "metadata": {},
   "source": [
    "## Test Case\n",
    "\n",
    "Optimize\n",
    "$$\n",
    "f(x, y) = \\frac{1}{2} [x, y]^T M [x, y]\n",
    "$$\n",
    "\n",
    "for some well-conditioned matrix $M \\in \\mathbb{R}^{n \\times n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "amino-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.test_ihvp import TestIHVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "purple-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_torch = TestIHVP()\n",
    "test_torch.setUp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "entire-roller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.6020, -1.2975],\n",
       "         [ 0.7429,  0.6762]], requires_grad=True),\n",
       " tensor([[ 0.7552, -1.2698],\n",
       "         [ 0.7202, -0.1917],\n",
       "         [ 1.5910,  0.7936]], requires_grad=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_torch.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "organic-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_torch.test_iterative_ihvp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "limiting-department",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2972, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_torch.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "excess-collection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4912, -0.5777],\n",
       "         [ 0.7830,  0.1143]], grad_fn=<ViewBackward>),\n",
       " tensor([[ 0.6828, -0.9290],\n",
       "         [ 0.1508, -0.1868],\n",
       "         [ 0.5814,  0.1581]], grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.grad(test_torch.out, test_torch.params, create_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-health",
   "metadata": {},
   "source": [
    "## TF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "altered-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allclose_tf(A, B, tol=1e-5):\n",
    "    return tf.reduce_sum((A - B)**2).numpy() < tol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "excessive-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.test_ihvp_tf import TestIHVP_TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "functional-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tf = TestIHVP_TF()\n",
    "test_tf.setUp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dramatic-starter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
       " array([[ 1.2110573 ,  0.01387285],\n",
       "        [-1.611183  ,  1.6539273 ]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(3, 2) dtype=float32, numpy=\n",
       " array([[ 1.6525732 , -0.5374252 ],\n",
       "        [-1.1671807 , -1.680566  ],\n",
       "        [ 1.2428781 , -0.05604479]], dtype=float32)>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tf.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "subject-population",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.5493422>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tf.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "respected-damage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 883.18it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 797.80it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 655.40it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 652.98it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 738.48it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 790.49it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 963.79it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 974.01it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 906.93it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 920.41it/s]\n"
     ]
    }
   ],
   "source": [
    "test_tf.test_iterative_ihvp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "little-hypothetical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tf.outer_tape._persistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "listed-mirror",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 819.33it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 796.17it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 693.52it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 747.30it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 756.22it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 937.27it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 968.70it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 719.44it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:01<00:00, 887.98it/s]\n",
      "IterativeIHVP_TF.get_ihvp: 100%|██████████| 1000/1000 [00:00<00:00, 1031.02it/s]\n"
     ]
    }
   ],
   "source": [
    "test_tf.setUp()\n",
    "ihvp = IterativeIHVPTF(test_tf.params, iters=1000)\n",
    "test_tf._test_ihvp(ihvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "insured-ivory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([-0.25477085, -0.05003049,  0.42217764, -0.08275922,  0.26389915,\n",
       "        -0.0652815 ,  0.40807134,  0.0514034 ,  0.03918216, -0.30609643],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([-0.44654477,  0.05398908, -0.04285225, -0.34855127, -0.37472948,\n",
       "        -0.18207447,  0.28177   ,  0.0738418 , -0.0641168 , -0.3288384 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([-0.35499635,  0.24794406,  0.41747937, -0.3864661 , -0.28803688,\n",
       "         0.986034  ,  0.28840446, -0.3360384 , -0.21421148,  0.03048006],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([ 0.30575866,  0.25215325, -0.17385244,  0.6436982 , -0.19871779,\n",
       "        -0.7207403 , -0.00875807,  0.5046706 ,  0.7557608 ,  0.38369173],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([ 0.55017054, -0.01878751, -0.8293436 ,  0.6875292 , -0.4026634 ,\n",
       "         0.02859233, -0.12260769,  0.41227382, -0.09372057,  0.41559717],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([-0.6968207 ,  0.2474686 ,  1.4189234 ,  0.5339929 ,  0.20882358,\n",
       "        -0.64907515, -0.4221962 , -0.15913557,  0.25359216, -0.7951548 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([ 0.22166218,  0.03998633, -0.03929004,  0.09877718,  0.21581343,\n",
       "        -0.26137626,  0.03721065,  0.08632388,  0.33019942, -0.14743885],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([ 0.24005552,  0.06542727,  0.15949443, -0.71610785, -0.19970608,\n",
       "         0.93572444,  0.20809501, -0.4867877 , -0.50420904, -0.02079348],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([ 0.311509  , -0.1691289 , -0.6775317 ,  0.02377936, -0.43241423,\n",
       "        -0.14998558,  0.2926751 ,  0.30390394, -0.04969106,  0.9121085 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([-0.14801826,  0.14081511,  0.06233174,  0.6872362 ,  0.2602288 ,\n",
       "        -0.26028013, -0.06930907, -0.24153732,  0.4759157 , -0.07968487],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvps = [ihvp.compute_hvp(v) for v in test_tf.vs]\n",
    "[tf.concat([tf.reshape(h, [-1]) for h in hvp], axis=0) for hvp in hvps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "raised-speaking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.7982388>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.multiply(tf.reshape(test_tf.params[0], [-1]), tf.reshape(test_tf.params[0], [-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "# 1. x and y are two parameter tensors\n",
    "x = tf.Variable(tf.random.normal(shape=(2, 2)))\n",
    "nx = x.shape.num_elements()\n",
    "y = tf.Variable(tf.random.normal(shape=(3, 2)))\n",
    "ny = y.shape.num_elements()\n",
    "n = nx + ny\n",
    "print(\"x:\", x)\n",
    "print(\"y:\", y)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-chile",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = [x, y]\n",
    "x_flat = tf.Variable(tf.reshape(x, -1))\n",
    "y_flat = tf.Variable(tf.reshape(y, -1))\n",
    "\n",
    "z = tf.Variable(tf.expand_dims(tf.Variable(tf.concat([x_flat, y_flat], -1)), 1))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.random.normal(shape=(n, n))\n",
    "M = tf.transpose(A) @ A + 0.01 * tf.linalg.eye(n)\n",
    "E, V = tf.linalg.eigh(M)\n",
    "emin_good = E[-1] / 5\n",
    "E = tf.maximum(E, emin_good)  # E_max/E_min <= 0.2\n",
    "if E[-1] > 1:\n",
    "    E = E / E[-1]\n",
    "M = V @ tf.linalg.diag(E) @ tf.transpose(V)\n",
    "M_inv = tf.linalg.inv(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective\n",
    "objective = 0.5 * tf.reduce_sum(tf.multiply(z, M @ z))\n",
    "objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true ihvp outputs\n",
    "vs, ihvp_true_flats = [], []\n",
    "for _ in range(10):\n",
    "    v = [tf.random.normal(p.shape) for p in params]\n",
    "    vs.append(v)\n",
    "    v_flat = tf.expand_dims(tf.concat([tf.reshape(v_i, -1) for v_i in v], -1), -1)\n",
    "    ihvp_true_flat = M_inv @ v_flat\n",
    "    ihvp_true_flats.append(ihvp_true_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs[0], ihvp_true_flats[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-adaptation",
   "metadata": {},
   "source": [
    "## TF2 Gradients & Hessians\n",
    "\n",
    "...are managed by `tf.GradientTape`. \n",
    "\n",
    "According to [this documentation](https://www.tensorflow.org/api_docs/python/tf/autodiff/ForwardAccumulator), it is more efficient to consider the `forwardprop` module when considering many-inputs-to-scalar-output NNs.\n",
    "The module also supports efficiently computing Jacobian-vector products (JVPs) and Hessian-vector products (HVPs) without explicitly constructing the Jacobian and the Hessian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_flats = [\n",
    "    tf.expand_dims(tf.concat([tf.reshape(v_i, -1) for v_i in v], -1), -1)\n",
    "    for v in vs\n",
    "]\n",
    "v_flat = v_flats[0]\n",
    "print(v_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-control",
   "metadata": {},
   "source": [
    "### forward-over-backward\n",
    "\n",
    "This could be faster, but requires that v's are known prior to the gradient computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-conducting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = tf.Variable(z)\n",
    "\n",
    "with tf.autodiff.ForwardAccumulator(z, v_flat) as acc:\n",
    "    with tf.GradientTape() as tape:\n",
    "        # objective = 0.5 * (tf.transpose(z) @ (M @ z))\n",
    "        objective = 0.5 * tf.reduce_sum(tf.multiply(z, M @ z))\n",
    "    grad = tape.gradient(objective, z)\n",
    "\n",
    "# gradient = M @ z\n",
    "print(allclose_tf(grad, M @ z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hessian-vector product with v = M @ v\n",
    "hvp = acc.jvp(grad)\n",
    "print(allclose_tf(hvp, M @ v_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-ebony",
   "metadata": {},
   "source": [
    "### backward-over-backward\n",
    "\n",
    "Compute $\\mathrm{HVP}(\\nabla_\\theta f_\\theta(z)) = H_\\theta \\nabla_\\theta f_\\theta(z) = (M)(Mz) = M^2z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-extreme",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = tf.Variable(z)\n",
    "with tf.GradientTape(persistent=True) as outer_tape:\n",
    "    with tf.GradientTape() as inner_tape:\n",
    "        objective = 0.5 * tf.reduce_sum(tf.multiply(z, M @ z))\n",
    "        grad = inner_tape.gradient(objective, z)  # 1 x p\n",
    "    print(allclose_tf(grad, M @ z))\n",
    "    jvp = tf.transpose(grad) @ grad  # 1 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "jvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvp = outer_tape.gradient(jvp, z)  # 1 x p\n",
    "print(allclose_tf(hvp, 2 * M @ (M @ z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-static",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector-valued objective\n",
    "loss_fn = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "z = tf.Variable(z)  # (p, 1)\n",
    "with tf.GradientTape(persistent=True) as outer_tape:\n",
    "    with tf.GradientTape() as inner_tape:\n",
    "        objective = loss_fn(M @ z, z)  # (p, )\n",
    "    grad = inner_tape.jacobian(objective, [z, z])  # (p, p, 1)\n",
    "#    print(allclose_tf(grad, M ))\n",
    "    #jvp = tf.transpose(grad) @ grad  # 1 x 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-quarter",
   "metadata": {},
   "source": [
    "The following is a workaround for keeping gradient tapes active (without Python contexts) from [here](https://stackoverflow.com/questions/62452614/how-to-reuse-the-inner-gradient-in-nested-gradient-tapes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_hvp(params, gradient, v, outer_tape):\n",
    "    \"\"\"Computes the HVP knowing gradients and their outer tape.\"\"\"\n",
    "    assert isinstance(v, list)\n",
    "    assert len(params) == len(gradient) == len(v)\n",
    "    outer_tape._push_tape()\n",
    "    jvp = [tf.reduce_sum(tf.multiply(g_i, v_i))\n",
    "           for g_i, v_i in zip(gradient, v)]\n",
    "    outer_tape._pop_tape()\n",
    "    return outer_tape.gradient(jvp, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def setup(x, y):\n",
    "    params = [x, y]\n",
    "    x_flat = tf.reshape(x, [-1])\n",
    "    y_flat = tf.reshape(y, [-1])\n",
    "\n",
    "    z = tf.expand_dims(tf.concat([x_flat, y_flat], -1), 1)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = setup(x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = setup(x, y)\n",
    "\n",
    "outer_tape = tf.GradientTape(persistent=True)\n",
    "outer_tape._push_tape()\n",
    "\n",
    "# Recorded by both outer and inner\n",
    "with tf.GradientTape() as inner_tape:\n",
    "    objective = 0.5 * (tf.transpose(z) @ (M @ z))\n",
    "\n",
    "grad = inner_tape.gradient(objective, [x, y])\n",
    "print(grad)\n",
    "#print(allclose_tf(grad, M @ z))\n",
    "\n",
    "# Stop recording by outer, for now\n",
    "outer_tape._pop_tape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvp = compute_hvp(z, grad, tf.identity(grad), outer_tape)\n",
    "print(allclose_tf(hvp, M @ (M @ z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_tape.watched_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v_flat in v_flats:\n",
    "    hvp = compute_hvp(z, grad, v_flat, outer_tape)\n",
    "    print(allclose_tf(hvp, M @ v_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close tapes when over\n",
    "inner_tape._tape = None\n",
    "outer_tape._tape = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.stop_gradient(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-cable",
   "metadata": {},
   "source": [
    "### forward-over-backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.autodiff.ForwardAccumulator(z, v_flat) as acc:\n",
    "    acc.watch(grad)\n",
    "    hvp = acc.jvp(grad)\n",
    "print(allclose_tf(hvp, M @ v_flat))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.losses.MSE(grad, M@z, reduction=tf.keras.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-bolivia",
   "metadata": {},
   "source": [
    "## Gradients: torch to TF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_torch.out\n",
    "\n",
    "x_torch, y_torch = test_torch.params\n",
    "\n",
    "grad_params_torch = torch.autograd.grad(test_torch.out, test_torch.params, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-france",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grad_params_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-location",
   "metadata": {},
   "source": [
    "### torch to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np, y_np = [t.detach().numpy() for t in test_torch.params]\n",
    "print(\"x:\", x_np)\n",
    "print(\"y:\", y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_np = test_torch.M.detach().numpy()\n",
    "M_inv_np = test_torch.M_inv.detach().numpy()\n",
    "print(M_np.shape, M_inv_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_params_np = [grad_param.detach().numpy() for grad_param in grad_params_torch]\n",
    "grad_params_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_np = [[v.detach().numpy() for v in v_params] \n",
    "         for v_params in test_torch.vs]\n",
    "vs_np[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-adelaide",
   "metadata": {},
   "source": [
    "### numpy to tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(x_np)\n",
    "y = tf.Variable(y_np)\n",
    "\n",
    "params = [x, y]\n",
    "x_flat = tf.reshape(x, -1)\n",
    "y_flat = tf.reshape(y, -1)\n",
    "\n",
    "z = tf.expand_dims(tf.concat([x_flat, y_flat], -1), 1)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = tf.constant(M_np)\n",
    "objective = 0.5 * (tf.transpose(z) @ (M @ z))\n",
    "print(\"tf2 objective == torch objective?\", np.allclose(objective.numpy(), test_torch.out.detach().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-respect",
   "metadata": {},
   "source": [
    "### tf2 gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    x_flat = tf.reshape(x, -1)\n",
    "    y_flat = tf.reshape(y, -1)\n",
    "    z = tf.expand_dims(tf.concat([x_flat, y_flat], -1), 1)\n",
    "    objective = 0.5 * (tf.transpose(z) @ (M @ z))\n",
    "grad_params = tape.gradient(objective, params)\n",
    "print(grad_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "grad_params_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-collectible",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_tf = [[tf.Variable(v) for v in v_param] for v_param in vs_np]\n",
    "vs_tf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(x_np)\n",
    "y = tf.Variable(y_np)\n",
    "params = [x, y]\n",
    "n_params = len(params)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as outer_tape:\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        x_flat = tf.reshape(x, -1)\n",
    "        y_flat = tf.reshape(y, -1)\n",
    "        z = tf.expand_dims(tf.concat([x_flat, y_flat], -1), 1)\n",
    "        objective = 0.5 * (tf.transpose(z) @ (M @ z))\n",
    "    grad_params = tape.gradient(objective, params)\n",
    "    print(\"grad_params:\", grad_params)\n",
    "\n",
    "    for v_param in vs_tf:  # repeat for 10 random v's\n",
    "        ihvp = v_param[:]\n",
    "        assert len(ihvp) == n_params\n",
    "        grad_params_ihvp = [\n",
    "            tf.reduce_sum(grad_params[i] * ihvp[i]) \n",
    "            for i in range(n_params)\n",
    "        ]\n",
    "        print(\"grad_params_ihvp:\", grad_params_ihvp)\n",
    "        break\n",
    "H_ihvp = outer_tape.gradient(grad_params_ihvp, params)\n",
    "print(\"H_ihvp:\", H_ihvp)\n",
    "for i in range(n_params):\n",
    "    ihvp[i] = v[i] + (1.0) * ihvp[i] - H_ihvp[i]\n",
    "    #ihvp[i] = ihvp[i].stop_gradient()\n",
    "print(\"ihvp:\", ihvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_torch, y_torch = test_torch.params\n",
    "grad_params_torch = torch.autograd.grad(test_torch.out, test_torch.params, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "v_torch = test_torch.vs[0]\n",
    "ihvp_torch = v_torch[:]\n",
    "for _ in range(1):\n",
    "    # Apply the recursion ihvp <- v + ihvp - H*ihvp\n",
    "    grad_params_ihvp_torch = [\n",
    "        grad_params_torch[i].view(-1) @ ihvp_torch[i].view(-1) for i in range(len(ihvp_torch))\n",
    "    ]\n",
    "    with torch.no_grad():\n",
    "        H_ihvp_torch = torch.autograd.grad(\n",
    "            grad_params_ihvp_torch, test_torch.params, create_graph=True\n",
    "        )\n",
    "        for i in range(len(ihvp_torch)):\n",
    "            ihvp_torch[i] = v_torch[i] + (1.0) * ihvp_torch[i] - H_ihvp_torch[i]\n",
    "            ihvp_torch[i] = ihvp_torch[i].detach()\n",
    "print(ihvp_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_params_torch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "ihvp_torch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_params_torch[0].view(-1) @ ihvp_torch[0].view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-boston",
   "metadata": {},
   "source": [
    "## TF2 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "    path='boston_housing.npz', test_split=0.2, seed=113\n",
    ")\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(13, )),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "outer_tape = tf.GradientTape(persistent=True)\n",
    "outer_tape._push_tape()\n",
    "\n",
    "# Recorded by both outer and inner\n",
    "x, y = iter(train.batch(8)).get_next()\n",
    "with tf.GradientTape() as inner_tape:\n",
    "    preds = model(x)\n",
    "    losses = loss_fn(preds[:, tf.newaxis], y[:, tf.newaxis])\n",
    "\n",
    "gradients = list(zip(*[\n",
    "    list(g) for g in inner_tape.jacobian(\n",
    "        losses, model.trainable_variables\n",
    "    )]))  # gradients per example (first) per layer\n",
    "assert len(gradients) == 8\n",
    "assert len(gradients[0]) == len(model.trainable_variables)\n",
    "mean_loss = tf.reduce_mean(losses)\n",
    "\n",
    "# Stop recording by outer, for now\n",
    "outer_tape._pop_tape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t.shape for t in model.trainable_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t.shape for t in gradients[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reshape(gradient[0], -1)[tf.newaxis, :] @ tf.reshape(v[0], -1)[:, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(tf.multiply(gradient[0], v[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hvp(params, gradient, v, outer_tape):\n",
    "    \"\"\"Computes the HVP knowing gradients and their outer tape.\"\"\"\n",
    "    assert isinstance(v, list)\n",
    "    assert len(params) == len(gradient) == len(v)\n",
    "    outer_tape._push_tape()\n",
    "    jvp = [tf.reduce_sum(tf.multiply(g_i, v_i))\n",
    "           for g_i, v_i in zip(gradient, v)]\n",
    "    outer_tape._pop_tape()\n",
    "    return outer_tape.gradient(jvp, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = [[tf.stop_gradient(tf.identity(g)) for g in gradient]\n",
    "      for gradient in gradients]  # influence\n",
    "# loop over batch; outer_tape is recycled\n",
    "for gradient, v in zip(gradients, vs):\n",
    "    hvp = compute_hvp(model.trainable_variables, gradient, v, outer_tape)\n",
    "    print([t.shape for t in hvp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.MSE\n",
    "loss_fn(predictions, y_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.MSE,\n",
    "    metrics=[\"mse\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, validation_split=0.1, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(x_test)\n",
    "\n",
    "print(\"predicted:\", predictions.numpy().squeeze()[:5])\n",
    "print(\"true:\", y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_flat = v_flats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-thumbnail",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v_flat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
